{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/null1902134/StableDiffusion/blob/main/automatic1111.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OFCYOzNjDX"
      },
      "source": [
        "# [Stable Diffusion WebUI Colab](https://github.com/ddPn08/stable-diffusion-webui-colab) by [ddPn08](https://github.com/ddpn08/)\n",
        "\n",
        "## Wiki\n",
        "https://github.com/ddPn08/automatic1111-colab/wiki\n",
        "\n",
        "<br />\n",
        "\n",
        "# Troubleshooting (不具合が発生したら)\n",
        "1. First, check the wiki and changelog. (まずは、Wikiと変更ログを確認してください。)\n",
        "  - [Wiki](https://github.com/ddPn08/automatic1111-colab/wiki)\n",
        "  - [CHANGELOG | 変更ログ](#scrollTo=moDR3lrJVsE8)\n",
        "\n",
        "2. If you still can't figure it out, open a Github issue. (それでもわからない場合はGithubのIssueを立ててください。)\n",
        "  - [Github Issue](https://github.com/ddPn08/automatic1111-colab/issues/new)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y4xxtQfuJiWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24eb50ce-6b39-435b-900c-b0e6d7ee0111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       545Mi       9.4Gi       1.0Mi       2.7Gi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi\n",
        "! nvcc -V\n",
        "! free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE45Pqn_N81E"
      },
      "source": [
        "## 1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXkcQu6OEAu"
      },
      "source": [
        "### 1.1 Clone repository\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#11-clone-repository) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#11-リポジトリのクローン)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "yzdbQDudNZ6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f03be1-bb44-415d-fe64-d25ccedb7517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 34968, done.\u001b[K\n",
            "remote: Total 34968 (delta 0), reused 0 (delta 0), pack-reused 34968 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34968/34968), 35.58 MiB | 16.32 MiB/s, done.\n",
            "Resolving deltas: 100% (24421/24421), done.\n",
            "/content/stable-diffusion-webui\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "repository_url = \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\"  # @param {type: \"string\"}\n",
        "webui_branch = \"master\"  # @param {type: \"string\"}\n",
        "\n",
        "! git clone {repository_url}\n",
        "%cd /content/stable-diffusion-webui\n",
        "! git checkout {webui_branch}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHgDng2c0FX"
      },
      "source": [
        "### 1.2 Setup models\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#12-setup-models) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#12-モデルのセットアップ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "Mls4_48XOrTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b67c2e-e617-4570-937f-677fb0b9b4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Set up the StableDiffusion model.\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "data_dir = \"/content/data\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Optional | Download the model if it isn't already in the `{data_dir}/models` folder**\n",
        "\n",
        "# @markdown Get huggingface access token from [here](https://huggingface.co/settings/tokens)\n",
        "auth_token = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "download_if_missing = False  # @param {type:\"boolean\"}\n",
        "# @markdown If you use the SD 2.1 model, select its config from the dropdown\n",
        "\n",
        "# @markdown model_url2, 3, config_url2, 3, vae_url2, 3 are option. <br>\n",
        "# @markdown If you have models, config or vae that you want to load at the same time, please enter them.\n",
        "model_url = \"https://huggingface.co/dreamlike-art/dreamlike-anime-1.0/resolve/main/dreamlike-anime-1.0.safetensors\" #@param [\"https://huggingface.co/dreamlike-art/dreamlike-anime-1.0/resolve/main/dreamlike-anime-1.0.safetensors\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "model_url2 = \"\" #@param [\"https://huggingface.co/dreamlike-art/dreamlike-anime-1.0/resolve/main/dreamlike-anime-1.0.safetensors\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "model_url3 = \"\" #@param [\"https://huggingface.co/dreamlike-art/dreamlike-anime-1.0/resolve/main/dreamlike-anime-1.0.safetensors\", \"https://huggingface.co/AdamOswald1/anything-v5.0/resolve/main/Anything-V3.0.ckpt\", \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\"] {allow-input: true}\n",
        "\n",
        "config_url = \"\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "config_url2 = \"\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "config_url3 = \"\" #@param [\"\", \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"] {allow-input: true}\n",
        "\n",
        "use_vae = False # @param {type:\"boolean\"}\n",
        "vae_url = \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\"] {allow-input: true}\n",
        "vae_url2 = \"\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\"] {allow-input: true}\n",
        "vae_url3 = \"\" #@param [\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt\"] {allow-input: true}\n",
        "\n",
        "urls = [model_url, model_url2, model_url3, config_url, config_url2, config_url3]\n",
        "vae_urls = [vae_url, vae_url2, vae_url3]\n",
        "\n",
        "# @markdown **Optional | Use Google Drive**\n",
        "mount_google_drive = True  # @param {type:\"boolean\"}\n",
        "data_dir_gdrive = \"/content/drive/MyDrive/AI/automatic1111\"  # @param {type:\"string\"}\n",
        "# @markdown If you load multiple models/config/vae, it is recommended to check force_model_download_locally\n",
        "force_model_download_locally = False  # @param {type:\"boolean\"}\n",
        "force_remount = False  # @param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "mount_success = False\n",
        "drive_path = \"/content/drive\"\n",
        "if mount_google_drive and not os.path.exists(drive_path):\n",
        "    from google.colab import drive\n",
        "\n",
        "    try:\n",
        "        drive.mount(drive_path, force_remount=force_remount)\n",
        "        os.makedirs(data_dir_gdrive, exist_ok=True)\n",
        "        ! rm -Rf {data_dir} && ln -s {data_dir_gdrive} {data_dir}\n",
        "        mount_success = True\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.pre.sh\"):\n",
        "    ! chmod +x {data_dir}/script.pre.sh\n",
        "    ! {data_dir}/script.pre.sh\n",
        "\n",
        "models_path = f\"{data_dir}/models\"\n",
        "output_path = f\"{data_dir}/outputs\"\n",
        "config_path = f\"{data_dir}/config\"\n",
        "scripts_path = f\"{data_dir}/scripts\"\n",
        "extensions_file_path = f\"{data_dir}/extensions.txt\"\n",
        "\n",
        "if force_model_download_locally:\n",
        "    models_path = \"/content/models\"\n",
        "\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "os.makedirs(scripts_path, exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/embeddings\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/Stable-diffusion\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/VAE\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/hypernetworks\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/dreambooth\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/Lora\", exist_ok=True)\n",
        "\n",
        "for script in os.listdir(scripts_path):\n",
        "    ! rm -Rf stable-diffusion-webui/scripts/{script} && ln -s {scripts_path}/{script} stable-diffusion-webui/scripts/{script}\n",
        "\n",
        "for dir in os.listdir(models_path):\n",
        "    if dir == \"embeddings\":\n",
        "        ! rm -Rf stable-diffusion-webui/embeddings && ln -s {models_path}/embeddings stable-diffusion-webui/embeddings\n",
        "    else:\n",
        "        ! rm -Rf stable-diffusion-webui/models/{dir} && ln -s {models_path}/{dir} stable-diffusion-webui/models/{dir}\n",
        "\n",
        "! rm -Rf stable-diffusion-webui/outputs && ln -s {data_dir}/outputs stable-diffusion-webui/outputs\n",
        "\n",
        "for filename in [\"config.json\", \"ui-config.json\"]:\n",
        "    ! rm -f stable-diffusion-webui/{filename}\n",
        "    filepath = f\"{config_path}/{filename}\"\n",
        "    if not os.path.exists(filepath):\n",
        "        if filename.endswith(\".json\"):\n",
        "            with open(filepath, mode=\"w\") as f:\n",
        "                f.write(\"{}\")\n",
        "        else:\n",
        "            ! touch {config_path}/{filename}\n",
        "    ! ln -s {config_path}/{filename} stable-diffusion-webui/{filename}\n",
        "\n",
        "if download_if_missing:\n",
        "    for url in urls:\n",
        "        filename = url.split(\"/\")[-1]\n",
        "        if not os.path.exists(f\"{models_path}/Stable-diffusion/{filename}\"):\n",
        "            ! curl -LJ {url} -o {models_path}/Stable-diffusion/{filename} {'-H \"Authorization: Bearer ' + auth_token + '\"' if auth_token else \"\"}\n",
        "    if use_vae:\n",
        "      for vae_url in vae_urls:\n",
        "        vae_filename = vae_url.split(\"/\")[-1]\n",
        "        if not os.path.exists(f\"{models_path}/VAE/{vae_filename}\"):\n",
        "            ! curl -LJ {vae_url} -o {models_path}/VAE/{vae_filename} {'-H \"Authorization: Bearer ' + auth_token + '\"' if auth_token else \"\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JkrcrPBza-M"
      },
      "source": [
        "## 2 - Advanced - Launch preferences\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-EN#2-launch-preferences) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-JP#2-起動設定)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "goUvyTZ4zd4l",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Command line arguments\n",
        "\n",
        "import os\n",
        "\n",
        "no_half = False  # @param {type:\"boolean\"}\n",
        "no_half_vae = True  # @param {type:\"boolean\"}\n",
        "allow_code = False  # @param {type:\"boolean\"}\n",
        "no_progressbar_hiding = False  # @param {type:\"boolean\"}\n",
        "medvram = False  # @param {type:\"boolean\"}\n",
        "lowvram = False  # @param {type:\"boolean\"}\n",
        "deepdanbooru = False  # @param {type:\"boolean\"}\n",
        "xformers = False  # @param {type:\"boolean\"}\n",
        "disable_opt_split_attention = False  # @param {type:\"boolean\"}\n",
        "gradio_queue = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown  <br >\n",
        "custom_arguments = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "run_string_with_variables = {\n",
        "    \"--no-half\": f\"{no_half}\",\n",
        "    \"--no-half-vae\": f\"{no_half_vae}\",\n",
        "    \"--allow-code\": f\"{allow_code}\",\n",
        "    \"--no-progressbar-hiding\": f\"{no_progressbar_hiding}\",\n",
        "    \"--medvram\": f\"{medvram}\",\n",
        "    \"--lowvram\": f\"{lowvram}\",\n",
        "    \"--deepdanbooru\": f\"{deepdanbooru}\",\n",
        "    \"--xformers\": f\"{xformers}\",\n",
        "    \"--disable-opt-split-attention\": f\"{disable_opt_split_attention}\",\n",
        "    \"--skip-torch-cuda-test\": \"True\" # Added this line\n",
        "}\n",
        "\n",
        "if use_vae:\n",
        "      for vae_url in vae_urls:\n",
        "        vae_filename = vae_url.split(\"/\")[-1]\n",
        "        if os.path.exists(f\"{models_path}/VAE/{vae_filename}\") and vae_filename:\n",
        "           key = \"--vae-path /content/stable-diffusion-webui/models/VAE/\" + vae_filename\n",
        "           run_string_with_variables[key] = f\"{use_vae}\"\n",
        "\n",
        "advanced_options = {k for (k, v) in run_string_with_variables.items() if v == \"True\"}\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Enable password authentication (Prevent other users from using the WebUI)\n",
        "\n",
        "# @markdown  <br >\n",
        "\n",
        "use_gradio_auth = False  # @param {type:\"boolean\"}\n",
        "gradio_auth_username = \"username\"  # @param {type:\"string\"}\n",
        "gradio_auth_password = \"password\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown # Advanced | Network preferences\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Optional | Ngrok Tunnel\n",
        "# @markdown Get token from [here](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "use_ngrok = False  # @param {type: \"boolean\"}\n",
        "load_token_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "ngrok_auth_token = \"\"  # @param {type: \"string\"}\n",
        "ngrok_region = \"default\"  # @param [\"default\", \"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/ngrok.txt\") and use_ngrok:\n",
        "    with open(f\"{data_dir}/ngrok.txt\", mode=\"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        if not ngrok_auth_token and len(lines) > 0:\n",
        "            ngrok_auth_token = lines[0].strip()\n",
        "        if ngrok_region == \"default\" and len(lines) > 1:\n",
        "            ngrok_region = lines[1].strip()\n",
        "\n",
        "with open(f\"{data_dir}/ngrok.txt\", mode=\"w\") as f:\n",
        "    f.write(f\"{ngrok_auth_token}\\n{ngrok_region}\")\n",
        "\n",
        "if not ngrok_region or ngrok_region == \"default\":\n",
        "    ngrok_region = \"us\"\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Extensions\n",
        "load_extensions_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "extensions = \"https://github.com/yfszzx/stable-diffusion-webui-images-browser, https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"  # @param {type:\"string\"}\n",
        "extensions = list(map(str.strip, extensions.split(\",\")))\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "# @markdown ## Save extensions to Google Drive\n",
        "# @markdown **Deprecated** (Unexpected errors may occur)\n",
        "save_extensions_to_gdrive = False  # @param {type:\"boolean\"}\n",
        "\n",
        "if save_extensions_to_gdrive:\n",
        "    os.makedirs(f\"{data_dir}/extensions\", exist_ok=True)\n",
        "    ! rm -Rf stable-diffusion-webui/extensions && ln -s {data_dir}/extensions stable-diffusion-webui/extensions\n",
        "\n",
        "if load_extensions_from_gdrive and extensions_file_path:\n",
        "    if os.path.exists(extensions_file_path):\n",
        "        with open(extensions_file_path, mode=\"r\") as f:\n",
        "            for s in f:\n",
        "                url = s.strip()\n",
        "                if url not in extensions:\n",
        "                    extensions.append(url)\n",
        "    with open(extensions_file_path, mode=\"w+\") as f:\n",
        "        f.write(\"\\n\".join(extensions))\n",
        "\n",
        "share_args = f\" --share {'--gradio-queue' if gradio_queue else ''}\"\n",
        "\n",
        "vars = \" \".join(advanced_options)\n",
        "if not use_ngrok:\n",
        "    vars += share_args\n",
        "elif ngrok_auth_token and ngrok_region:\n",
        "    vars += f\" --ngrok {ngrok_auth_token} --ngrok-region {ngrok_region}\"\n",
        "elif not ngrok_auth_token or not ngrok_region:\n",
        "    vars += share_args\n",
        "\n",
        "if use_gradio_auth:\n",
        "    vars += f\" --gradio-auth {gradio_auth_username}:{gradio_auth_password}\"\n",
        "\n",
        "vars += f\" --styles-file {data_dir}/config/styles.csv\"\n",
        "\n",
        "os.environ[\"COMMANDLINE_ARGS\"] = f\"{vars} {custom_arguments}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htQtwGXHTaob"
      },
      "source": [
        "## 3 - Launch WebUI\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-EN#set-up-the-environment) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-JP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ao2t5h5qG9HD",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180e2b3e-fd58-4f83-e1d2-a35bbe84e49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui/extensions\n",
            "Cloning into 'stable-diffusion-webui-images-browser'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 143 (delta 25), reused 21 (delta 21), pack-reused 109 (from 1)\u001b[K\n",
            "Receiving objects: 100% (143/143), 37.92 KiB | 546.00 KiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Cloning into 'a1111-sd-webui-tagcomplete'...\n",
            "remote: Enumerating objects: 2619, done.\u001b[K\n",
            "remote: Counting objects: 100% (900/900), done.\u001b[K\n",
            "remote: Compressing objects: 100% (381/381), done.\u001b[K\n",
            "remote: Total 2619 (delta 590), reused 551 (delta 519), pack-reused 1719 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2619/2619), 15.30 MiB | 19.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1701/1701), done.\n",
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  131M  100  131M    0     0  40.7M      0  0:00:03  0:00:03 --:--:-- 40.7M\n",
            "PREFIX=/opt/conda\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /opt/conda\n",
            "Collecting tensorrt\n",
            "  Downloading tensorrt-10.13.2.6.tar.gz (40 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton\n",
            "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting tensorrt_cu13==10.13.2.6 (from tensorrt)\n",
            "  Downloading tensorrt_cu13-10.13.2.6.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_libs==10.13.2.6 (from tensorrt_cu13==10.13.2.6->tensorrt)\n",
            "  Downloading tensorrt_cu13_libs-10.13.2.6.tar.gz (704 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_bindings==10.13.2.6 (from tensorrt_cu13==10.13.2.6->tensorrt)\n",
            "  Downloading tensorrt_cu13_bindings-10.13.2.6-cp310-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
            "Collecting nvidia-cuda-runtime-cu13 (from tensorrt_cu13_libs==10.13.2.6->tensorrt_cu13==10.13.2.6->tensorrt)\n",
            "  Downloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl.metadata (225 bytes)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.10/site-packages (from triton) (75.1.0)\n",
            "Downloading tensorrt_cu13_bindings-10.13.2.6-cp310-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl (1.2 kB)\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.13.2.6-py2.py3-none-any.whl size=46434 sha256=21d13f388f908395eedf6918ac6c0b48cbb8c70808b59abceff942cd47d620b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/93/db/7cc8a16e287cf908a50600d968c5ee1ae8d65a4d8959327a64\n",
            "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.13.2.6-py2.py3-none-any.whl size=17436 sha256=9864dd0d21288a4b1d8a128af5ad02f53985068d86cbd3ceacc44b57b803905f\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/55/3a/fc2719bec8ce33962dd5dc60ab0cfceb67284a9fcdc3575b4b\n",
            "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.13.2.6-py2.py3-none-manylinux_2_28_x86_64.whl size=2740427176 sha256=044468b0705728c0c8f0e95325ba881ff3e23bd2eebce0b1e628953ff90bbb5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e7/06/6bfdcf06e445aa35b521ec9221906f4e702eb95c6f531bd78e\n",
            "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
            "Installing collected packages: tensorrt_cu13_bindings, nvidia-cuda-runtime-cu13, triton, tensorrt_cu13_libs, tensorrt_cu13, tensorrt\n",
            "Successfully installed nvidia-cuda-runtime-cu13-0.0.0a0 tensorrt-10.13.2.6 tensorrt_cu13-10.13.2.6 tensorrt_cu13_bindings-10.13.2.6 tensorrt_cu13_libs-10.13.2.6 triton-3.4.0\n",
            "Python 3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Installing torch and torchvision\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.1.2)\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions (from torch==2.1.2)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from torch==2.1.2)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.1.2)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.1.2)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.1.2)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from torchvision==0.16.2)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.2) (2.32.3)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.16.2)\n",
            "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2)\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.2) (2024.8.30)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, triton, jinja2, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.7.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pillow-11.3.0 sympy-1.14.0 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0 typing-extensions-4.15.0\n",
            "Installing clip\n",
            "Installing open_clip\n",
            "Cloning assets into /content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-webui-assets'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 20 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 132.70 KiB | 849.00 KiB/s, done.\n",
            "Cloning Stable Diffusion into /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...\n",
            "remote: Enumerating objects: 586, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 586 (delta 2), reused 0 (delta 0), pack-reused 579 (from 5)\u001b[K\n",
            "Receiving objects: 100% (586/586), 73.45 MiB | 21.55 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "Cloning Stable Diffusion XL into /content/stable-diffusion-webui/repositories/generative-models...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/generative-models'...\n",
            "remote: Enumerating objects: 1108, done.\u001b[K\n",
            "remote: Counting objects: 100% (519/519), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 1108 (delta 417), reused 365 (delta 365), pack-reused 589 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1108/1108), 86.65 MiB | 22.62 MiB/s, done.\n",
            "Resolving deltas: 100% (578/578), done.\n",
            "Cloning K-diffusion into /content/stable-diffusion-webui/repositories/k-diffusion...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/k-diffusion'...\n",
            "remote: Enumerating objects: 1350, done.\u001b[K\n",
            "remote: Counting objects: 100% (1350/1350), done.\u001b[K\n",
            "remote: Compressing objects: 100% (444/444), done.\u001b[K\n",
            "remote: Total 1350 (delta 951), reused 1254 (delta 899), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1350/1350), 233.36 KiB | 1.82 MiB/s, done.\n",
            "Resolving deltas: 100% (951/951), done.\n",
            "Cloning BLIP into /content/stable-diffusion-webui/repositories/BLIP...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 277 (delta 145), reused 137 (delta 137), pack-reused 94 (from 1)\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.04 MiB | 18.66 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Installing requirements\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   512  100   512    0     0    967      0 --:--:-- --:--:-- --:--:--   967\n"
          ]
        }
      ],
      "source": [
        "# @markdown ## Setup environment\n",
        "# @markdown This may take up to 5 minutes\n",
        "\n",
        "\n",
        "%cd /content/stable-diffusion-webui/extensions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "for extension in extensions:\n",
        "    if extension.startswith(\"#\"):\n",
        "        continue\n",
        "    ! git clone {extension}\n",
        "    extension_name, _ = os.path.splitext(extension.split(\"/\")[-1])\n",
        "    if not os.path.isdir(extension_name):\n",
        "      ! git clone {extension}\n",
        "    else:\n",
        "      ! cd {extension_name} && git fetch\n",
        "\n",
        "%cd /content\n",
        "\n",
        "conda_dir = \"/opt/conda\"  # @param{type:\"string\"}\n",
        "conda_bin = os.path.join(conda_dir, \"bin\", \"conda\")\n",
        "\n",
        "if not os.path.exists(conda_bin):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-py310_24.9.2-0-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-py310_24.9.2-0-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-py310_24.9.2-0-Linux-x86_64.sh -b -f -p {conda_dir}\n",
        "    ! rm Miniconda3-py310_24.9.2-0-Linux-x86_64.sh\n",
        "\n",
        "\n",
        "install_script = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "cd stable-diffusion-webui\n",
        "python3 -m pip install --upgrade tensorrt triton\n",
        "python -c 'from launch import prepare_environment; prepare_environment()'\n",
        "\"\"\"\n",
        "\n",
        "! {install_script}\n",
        "\n",
        "# @markdown\n",
        "# @markdown ## Optional | Apply low RAM patch\n",
        "apply_lowram_patch = True  # @param {type: \"boolean\"}\n",
        "\n",
        "if apply_lowram_patch:\n",
        "    patches_dir = \"/content/patches\"\n",
        "    os.makedirs(patches_dir, exist_ok=True)\n",
        "    ! cd {patches_dir} && curl -LO https://raw.githubusercontent.com/ddPn08/automatic1111-colab/main/patches/stablediffusion-lowram.patch\n",
        "    ! cd /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai && git apply {patches_dir}/stablediffusion-lowram.patch\n",
        "\n",
        "\n",
        "os.environ[\n",
        "    \"LD_LIBRARY_PATH\"\n",
        "] = f\"{os.environ['LD_LIBRARY_PATH']}:/usr/local/envs/automatic/lib\"\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.post.sh\"):\n",
        "    ! chmod +x {data_dir}/script.post.sh\n",
        "    ! {data_dir}/script.post.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dk3SW4sigrgD",
        "outputId": "232fd48f-04a6-4fa5-d2e9-106f917ed300",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y4ebYsPqTrGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5cc6c2-6dcb-4402-8608-36d99b8e2a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui\n",
            "Already up to date.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `0`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "Python 3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Launching Web UI with arguments: --disable-model-loading-ram-optimization --skip-torch-cuda-test --no-half-vae --share --gradio-queue --styles-file /content/data/config/styles.csv\n",
            "/opt/conda/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "no module 'xformers'. Processing without...\n",
            "no module 'xformers'. Processing without...\n",
            "No module 'xformers'. Proceeding without it.\n",
            "Warning: caught exception 'Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx', memory monitor disabled\n",
            "Tag Autocomplete: Creating frequency database\n",
            "Tag Autocomplete: Database successfully created\n",
            "Tag Autocomplete: Could not locate model-keyword extension, Lora trigger word completion will be limited to those added through the extra networks menu.\n",
            "Checkpoint Anime_v2.safetensors [67cf8b0ff1] not found; loading fallback Anime_v2.safetensors\n",
            "/content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser/scripts/images_history.py:214: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  history_gallery = gr.Gallery(show_label=False, elem_id=tabname + \"_images_history_gallery\").style(grid=opts.images_history_page_columns)\n",
            "/content/stable-diffusion-webui/extensions/stable-diffusion-webui-images-browser/scripts/images_history.py:214: GradioDeprecationWarning: The 'grid' parameter will be deprecated. Please use 'columns' in the constructor instead.\n",
            "  history_gallery = gr.Gallery(show_label=False, elem_id=tabname + \"_images_history_gallery\").style(grid=opts.images_history_page_columns)\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors: Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://6ff3ca12b70a7e52ac.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 24.2s (import torch: 5.3s, import gradio: 1.4s, setup paths: 1.1s, initialize shared: 0.3s, other imports: 1.0s, list SD models: 3.2s, load scripts: 4.0s, create ui: 5.7s, gradio launch: 2.1s).\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/anythingelseV4_v45.safetensors: 67cf8b0ff118af77a227e4cf796ce545f31cd83f6f9df3d187efe694655e38ba\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize.py\", line 149, in load_model\n",
            "    shared.sd_model  # noqa: B018\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize.py\", line 149, in load_model\n",
            "    shared.sd_model  # noqa: B018\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Applying attention optimization: InvokeAI... done.\n",
            "Exception in thread Thread-2 (load_model):\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize.py\", line 154, in load_model\n",
            "    devices.first_time_calculation()\n",
            "  File \"/content/stable-diffusion-webui/modules/devices.py\", line 277, in first_time_calculation\n",
            "    linear(x)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/networks.py\", line 584, in network_Linear_forward\n",
            "    return originals.Linear_forward(self, input)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "RuntimeError: \"addmm_impl_cpu_\" not implemented for 'Half'\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/anythingelseV4_v45.safetensors: 6e430eb51421ce5bf18f04e2dbe90b2cad437311948be4ef8c33658a73c86b2a\n",
            "6e430eb51421ce5bf18f04e2dbe90b2cad437311948be4ef8c33658a73c86b2a\n",
            "Loading weights [6e430eb514] from /content/stable-diffusion-webui/models/Stable-diffusion/anythingelseV4_v45.safetensors\n",
            "Loading weights [6e430eb514] from /content/stable-diffusion-webui/models/Stable-diffusion/anythingelseV4_v45.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_settings.py\", line 316, in <lambda>\n",
            "    fn=lambda value, k=k: self.run_settings_single(value, key=k),\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_settings.py\", line 95, in run_settings_single\n",
            "    if value is None or not opts.set(key, value):\n",
            "  File \"/content/stable-diffusion-webui/modules/options.py\", line 165, in set\n",
            "    option.onchange()\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 14, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize_util.py\", line 181, in <lambda>\n",
            "    shared.opts.onchange(\"sd_model_checkpoint\", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "changing setting sd_model_checkpoint to anythingelseV4_v45.safetensors: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/options.py\", line 165, in set\n",
            "    option.onchange()\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 14, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize_util.py\", line 181, in <lambda>\n",
            "    shared.opts.onchange(\"sd_model_checkpoint\", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui.py\", line 1165, in <lambda>\n",
            "    update_image_cfg_scale_visibility = lambda: gr.update(visible=shared.sd_model and shared.sd_model.cond_stage_key == \"edit\")\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui.py\", line 1165, in <lambda>\n",
            "    update_image_cfg_scale_visibility = lambda: gr.update(visible=shared.sd_model and shared.sd_model.cond_stage_key == \"edit\")\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 103, in txt2img\n",
            "    p = txt2img_create_processing(id_task, request, *args)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 21, in txt2img_create_processing\n",
            "    sd_model=shared.sd_model,\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 103, in txt2img\n",
            "    p = txt2img_create_processing(id_task, request, *args)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 21, in txt2img_create_processing\n",
            "    sd_model=shared.sd_model,\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 787, in pages_html\n",
            "    create_html()\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in create_html\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 783, in <listcomp>\n",
            "    ui.pages_contents = [pg.create_html(ui.tabname) for pg in ui.stored_extra_pages]\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in create_html\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/modules/ui_extra_networks.py\", line 591, in <dictcomp>\n",
            "    self.items = {x[\"name\"]: x for x in items_list}\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 82, in list_items\n",
            "    item = self.create_item(name, index)\n",
            "  File \"/content/stable-diffusion-webui/extensions-builtin/Lora/ui_extra_networks_lora.py\", line 63, in create_item\n",
            "    if shared.opts.lora_show_all or not enable_filter or not shared.sd_model:\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 850, in process_images\n",
            "    sd_models.apply_token_merging(p.sd_model, 0)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 263, in sd_model\n",
            "    return shared.sd_model\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 850, in process_images\n",
            "    sd_models.apply_token_merging(p.sd_model, 0)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 263, in sd_model\n",
            "    return shared.sd_model\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(zphkcb6i2weo4gc)', <gradio.routes.Request object at 0x7bca884f1f90>, 'magumin', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "        sd_models.reload_model_weights()\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "        load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "        sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "        return constructor(**params)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "        super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "        self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "        self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "        return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "        return self._apply(lambda t: t.cuda(device))\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "        module._apply(fn)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "        module._apply(fn)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "        param_applied = fn(param)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "        return self._apply(lambda t: t.cuda(device))\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "        torch._C._cuda_init()\n",
            "    RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "---\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 103, in txt2img\n",
            "    p = txt2img_create_processing(id_task, request, *args)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 21, in txt2img_create_processing\n",
            "    sd_model=shared.sd_model,\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 103, in txt2img\n",
            "    p = txt2img_create_processing(id_task, request, *args)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 21, in txt2img_create_processing\n",
            "    sd_model=shared.sd_model,\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "Loading weights [67cf8b0ff1] from /content/stable-diffusion-webui/models/Stable-diffusion/Anime_v2.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "creating model quickly: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 850, in process_images\n",
            "    sd_models.apply_token_merging(p.sd_model, 0)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 263, in sd_model\n",
            "    return shared.sd_model\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 820, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Failed to create model quickly; will retry using slow method.\n",
            "loading stable diffusion model: RuntimeError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "    sd_models.reload_model_weights()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "    load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "    self._bootstrap_inner()\n",
            "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/gradio/utils.py\", line 707, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "    res = list(func(*args, **kwargs))\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "    processed = processing.process_images(p)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 850, in process_images\n",
            "    sd_models.apply_token_merging(p.sd_model, 0)\n",
            "  File \"/content/stable-diffusion-webui/modules/processing.py\", line 263, in sd_model\n",
            "    return shared.sd_model\n",
            "  File \"/content/stable-diffusion-webui/modules/shared_items.py\", line 175, in sd_model\n",
            "    return modules.sd_models.model_data.get_sd_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 693, in get_sd_model\n",
            "    load_model()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "    sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "    return constructor(**params)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "    super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "    self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "    self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "  File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "\n",
            "Stable diffusion model failed to load\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(q006bjuaqsvr4mb)', <gradio.routes.Request object at 0x7bca885e6a70>, 'magumin', '', [], 1, 1, 7, 512, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 830, in process_images\n",
            "        sd_models.reload_model_weights()\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 977, in reload_model_weights\n",
            "        load_model(checkpoint_info, already_loaded_state_dict=state_dict)\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 829, in load_model\n",
            "        sd_model = instantiate_from_config(sd_config.model, state_dict)\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 775, in instantiate_from_config\n",
            "        return constructor(**params)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 550, in __init__\n",
            "        super().__init__(conditioning_key=conditioning_key, *args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 92, in __init__\n",
            "        self.model = DiffusionWrapper(unet_config, conditioning_key)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1314, in __init__\n",
            "        self.diffusion_model = instantiate_from_config(diff_model_config)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/util.py\", line 89, in instantiate_from_config\n",
            "        return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict())).cuda()\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in cuda\n",
            "        return self._apply(lambda t: t.cuda(device))\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "        module._apply(fn)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n",
            "        module._apply(fn)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n",
            "        param_applied = fn(param)\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 918, in <lambda>\n",
            "        return self._apply(lambda t: t.cuda(device))\n",
            "      File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "        torch._C._cuda_init()\n",
            "    RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Run script\n",
        "# @markdown keep in mind that this script is set to run for ever.\n",
        "# @markdown > ※注意 このスクリプトは永久に実行されます。\n",
        "\n",
        "# @markdown\n",
        "\n",
        "# @markdown ### Important - click the public URL to launch WebUI in another tab\n",
        "# @markdown > ### 重要 - 公開URLをクリックしてWebUIを起動してください\n",
        "\n",
        "# @markdown ![](https://user-images.githubusercontent.com/71378929/189563599-6df78bcf-133b-41e8-a55d-8ca3783cd933.png)\n",
        "\n",
        "import os\n",
        "os.environ['MPLBACKEND'] = 'agg' # Set the MPLBACKEND environment variable\n",
        "\n",
        "%cd /content/stable-diffusion-webui/\n",
        "! git pull\n",
        "\n",
        "run_script = f\"\"\"\n",
        "eval \"$({conda_bin} shell.bash hook)\"\n",
        "accelerate launch --num_cpu_threads_per_process 1 launch.py --disable-model-loading-ram-optimization\n",
        "\"\"\"\n",
        "! {run_script}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moDR3lrJVsE8"
      },
      "source": [
        "# CHANGELOG (変更ログ)\n",
        "\n",
        "## 2022/12/18 BREAKING CHANGE\n",
        "モデル等のディレクトリの構造を変更しました。くわしくは[こちら](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-JP)  \n",
        "Changed the directory structure of models etc. For details [here](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-EN)  \n",
        "\n",
        "## 2023/01/28\n",
        "- Simplified Python environment setup. / Python環境のセットアップをより簡潔にしました。\n",
        "- Removed Tailscale option. / Tailscaleオプションを削除しました。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f3fb6862b547830c34fbd0390b87507e21782526fd5ca25cfe7dc4f2b0fdae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}